{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**PCA: Principal Component Analysis**\n",
        "\n",
        "Here, I am implementing PCA. The idea is to reduce the Dimentions of the Speaker Data before implementing KNN on it in order to get better and refined results. After experimenting the final results on the speaker dataset shall be displayed in the Report."
      ],
      "metadata": {
        "id": "0oQfMvMzMWD2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1:**\n",
        "The first step is to standardise the data we are getting. The goal is to have the N(0,1) type of distribution i.e. mean=0 and variance=1"
      ],
      "metadata": {
        "id": "suhU3N8iNB6W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "IgwtM4XXMK3H"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def standardise_data(dataset):\n",
        "  mean=np.mean(dataset,axis=0) #Mean\n",
        "  std_dev=np.std(dataset,axis=0) #Standard Deviation\n",
        "  std_data=(dataset-mean)/std_dev #Standardised Data\n",
        "\n",
        "  return std_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2:**\n",
        "\n",
        "Done with Standardising the Data, now Covariance Matrix of this data is to be made."
      ],
      "metadata": {
        "id": "Hx5MwJ8nNyV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Covariance matrix\n",
        "\n",
        "def covariance_matrix(dataset):\n",
        "  m=dataset.shape[0] #no of samples in the dataset\n",
        "  cov_matrix=np.dot(dataset.T,dataset)/(m-1) #Covariance Matrix\n",
        "\n",
        "  return cov_matrix"
      ],
      "metadata": {
        "id": "epwNl0XnODnK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3:**\n",
        "\n",
        "Here, comes the main part. Calculation of the Eigenvalues and Eigenvectors of the Covariance Matrix. These serve as the parameters to decide which features to drp in the reduction of dimentionality"
      ],
      "metadata": {
        "id": "WIMKexx0Oo7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Eigenvalues and Eigenvectors\n",
        "\n",
        "def eigenvalues_eigenvectors(cov_matrix):\n",
        "  eigenvalues,eigenvectors=np.linalg.eig(cov_matrix)\n",
        "\n",
        "  return eigenvalues,eigenvectors"
      ],
      "metadata": {
        "id": "_WE-iVZqOlyp"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4:**\n",
        "\n",
        "Now the eigenvalues and eigenvectors are to be sorted"
      ],
      "metadata": {
        "id": "9coJXo6UPIaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_eigenpairs(eigenvalues,eigenvectors):\n",
        "  sorted_indices=np.argsort(eigenvalues)[::-1] #Sorting in descending order\n",
        "  sorted_eigenvalues=eigenvalues[sorted_indices]\n",
        "  sorted_eigenvectors=eigenvectors[:,sorted_indices]\n",
        "\n",
        "  return sorted_eigenvalues,sorted_eigenvectors"
      ],
      "metadata": {
        "id": "1khHc8_GS-pc"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5:**\n",
        "\n",
        "Projecting the Dataset on new coordinate system with top n components. On the actual dataset, the value of n will be varied and experiment results will be compiled and presented."
      ],
      "metadata": {
        "id": "AtpUo5CuQoUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def project_dataset_to_new_plane(X, eigenvectors, top_n=1):\n",
        "  W=eigenvectors[:,:top_n]\n",
        "\n",
        "  projected_data=np.dot(X,W)\n",
        "\n",
        "  return projected_data"
      ],
      "metadata": {
        "id": "Uv3vJ93_RDfs"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing with a random dataset"
      ],
      "metadata": {
        "id": "IgfJtG2iRoFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing\n",
        "data = np.array([[2.5, 2.4],\n",
        "                     [0.5, 0.7],\n",
        "                     [2.2, 2.9],\n",
        "                     [1.9, 2.2],\n",
        "                     [3.1, 3.0],\n",
        "                     [2.3, 2.7],\n",
        "                     [2.0, 1.6],\n",
        "                     [1.0, 1.1],\n",
        "                     [1.5, 1.6],\n",
        "                     [1.1, 0.9]])\n",
        "\n",
        "standardized_data = standardise_data(data)\n",
        "print(\"Standardized Data:\\n\", standardized_data)\n",
        "\n",
        "cov_matrix_result = covariance_matrix(standardized_data)\n",
        "print(\"Covariance Matrix:\\n\", cov_matrix_result)\n",
        "\n",
        "eigenvalues, eigenvectors = eigenvalues_eigenvectors(cov_matrix_result)\n",
        "print(\"Eigenvalues:\\n\", eigenvalues)\n",
        "print(\"Eigenvectors:\\n\", eigenvectors)\n",
        "\n",
        "sorted_eigenvalues, sorted_eigenvectors = sort_eigenpairs(eigenvalues, eigenvectors)\n",
        "print(\"Sorted Eigenvalues:\\n\", sorted_eigenvalues)\n",
        "print(\"Sorted Eigenvectors:\\n\", sorted_eigenvectors)\n",
        "\n",
        "projected_data = project_dataset_to_new_plane(standardized_data, sorted_eigenvectors)\n",
        "print(\"Projected Data:\\n\", projected_data)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNuWmEncRuAX",
        "outputId": "108c825b-ff00-4c3d-8517-77c54131faf0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standardized Data:\n",
            " [[ 0.92627881  0.61016865]\n",
            " [-1.7585873  -1.506743  ]\n",
            " [ 0.52354889  1.23278973]\n",
            " [ 0.12081898  0.36112022]\n",
            " [ 1.73173864  1.35731394]\n",
            " [ 0.6577922   0.9837413 ]\n",
            " [ 0.25506228 -0.38602507]\n",
            " [-1.08737078 -1.00864614]\n",
            " [-0.41615425 -0.38602507]\n",
            " [-0.95312747 -1.25769457]]\n",
            "Covariance Matrix:\n",
            " [[1.11111111 1.0288103 ]\n",
            " [1.0288103  1.11111111]]\n",
            "Eigenvalues:\n",
            " [0.08230081 2.13992141]\n",
            "Eigenvectors:\n",
            " [[-0.70710678 -0.70710678]\n",
            " [ 0.70710678 -0.70710678]]\n",
            "Sorted Eigenvalues:\n",
            " [2.13992141 0.08230081]\n",
            "Sorted Eigenvectors:\n",
            " [[-0.70710678 -0.70710678]\n",
            " [-0.70710678  0.70710678]]\n",
            "Projected Data:\n",
            " [[-1.08643242]\n",
            " [ 2.3089372 ]\n",
            " [-1.24191895]\n",
            " [-0.34078247]\n",
            " [-2.18429003]\n",
            " [-1.16073946]\n",
            " [ 0.09260467]\n",
            " [ 1.48210777]\n",
            " [ 0.56722643]\n",
            " [ 1.56328726]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing by creating a synthetic dataset"
      ],
      "metadata": {
        "id": "7kSYWTuET-uU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_dataset(n_samples=100, n_features=5):\n",
        "    np.random.seed(42)\n",
        "    feature_1 = np.random.normal(10, 2, n_samples)\n",
        "    feature_2 = feature_1 + np.random.normal(0, 1, n_samples)\n",
        "    feature_3 = np.random.normal(20, 5, n_samples)\n",
        "    feature_4 = feature_3 * 0.5 + np.random.normal(0, 2, n_samples)\n",
        "    feature_5 = np.random.normal(50, 10, n_samples)\n",
        "    return np.column_stack((feature_1, feature_2, feature_3, feature_4, feature_5))\n"
      ],
      "metadata": {
        "id": "-a5cPF-zT-J2"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Just a try\n",
        "def  main():\n",
        "  X=generate_dataset()\n",
        "  #print(\"Dataset:\\n\",dataset)\n",
        "\n",
        "  X_std=standardise_data(X)\n",
        "  #print(\"Standardised Dataset:\\n\",X_std)\n",
        "\n",
        "  cov_matrix_result=covariance_matrix(X_std)\n",
        "  #print(\"Covariance Matrix:\\n\",cov_matrix_result)\n",
        "\n",
        "  eigenvalues,eigenvectors=eigenvalues_eigenvectors(cov_matrix_result)\n",
        "  #print(\"Eigenvalues:\\n\",eigenvalues)\n",
        "  #print(\"Eigenvectors:\\n\",eigenvectors)\n",
        "\n",
        "  sorted_eigenvalues,sorted_eigenvectors=sort_eigenpairs(eigenvalues,eigenvectors)\n",
        "  #print(\"Sorted Eigenvalues:\\n\",sorted_eigenvalues)\n",
        "  #print(\"Sorted Eigenvectors:\\n\",sorted_eigenvectors)\n",
        "\n",
        "  explained_variance=sorted_eigenvalues/np.sum(sorted_eigenvalues)\n",
        "  print(\"Explained Variance:\\n\",explained_variance)\n",
        "\n",
        "  cumulative_variance=np.cumsum(explained_variance)\n",
        "  print(\"Cumulative Variance:\\n\",cumulative_variance)\n",
        "\n"
      ],
      "metadata": {
        "id": "keOj3BcCUDuK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}